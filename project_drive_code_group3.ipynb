{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a026bb7-63de-4d47-bfc2-2c269836d2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats! You selected the correct training images folder :)\n",
      "Congrats! You selected the correct training masks folder :)\n",
      "Congrats! You selected the correct training segmentations folder :)\n",
      "Congrats! You selected the correct secret test set folder :)\n"
     ]
    }
   ],
   "source": [
    "# data paths Lobke\n",
    "data_path_training_images = 'training/images'\n",
    "data_path_training_masks = 'training/mask'\n",
    "data_path_training_segmentations = 'training/1st_manual'\n",
    "data_path_secret_test = 'secret_test'\n",
    "\n",
    "\n",
    "# check if data_path exists:\n",
    "import os\n",
    "\n",
    "if not os.path.exists(data_path_training_images):\n",
    "    print(\"Please update your images data path to an existing folder.\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct training images folder :)\")\n",
    "\n",
    "if not os.path.exists(data_path_training_masks):\n",
    "    print(\"Please update your masks data path to an existing folder.\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct training masks folder :)\")\n",
    "\n",
    "if not os.path.exists(data_path_training_segmentations):\n",
    "    print(\"Please update your segmentations data path to an existing folder.\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct training segmentations folder :)\")\n",
    "    \n",
    "if not os.path.exists(data_path_secret_test):\n",
    "    print(\"Please update your secret test set data path to an existing folder.\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct secret test set folder :)\")\n",
    "\n",
    "\n",
    "# # weights and biases:\n",
    "# import wandb\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d782007-275f-4d8a-82bb-1798fc3a8cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import monai\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Compose, LoadImaged, ScaleIntensityd, ToTensord, RandFlipd, RandSpatialCropSamplesd, EnsureChannelFirstd, Lambdad, Transposed\n",
    "from monai.data import DataLoader, CacheDataset, ITKWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from monai.transforms import Transform\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for important parameters\n",
    "\n",
    "# data parameters\n",
    "num_test_files = 2\n",
    "num_validation_files = 2\n",
    "num_train_files = 20 - num_test_files - num_validation_files\n",
    "# roi_size = 192          # region of interest size\n",
    "trans_prob = 0.5        # transform probability\n",
    "batch_size = 2\n",
    "\n",
    "# model parameters\n",
    "# num_epochs = 1000 # train for at least 4000 epochs, but no clear overfitting at 10000 epochs\n",
    "validation_wait = 10\n",
    "\n",
    "# hyperparameter values for experiments\n",
    "num_epochssave = [1000, 2000, 4000, 8000, 16000]\n",
    "# num_epochs = max(num_epochssave)\n",
    "# lossfunctions = [monai.losses.DiceLoss(sigmoid=True, include_background=False), monai.losses.DiceCELoss(sigmoid=True, include_background=False)]\n",
    "# lossfunctionsnames = [\"Dice\", \"DiceCE\"]\n",
    "# roi_sizes = [32, 64, 128, 256]\n",
    "\n",
    "# for testing\n",
    "num_epochssave = 5\n",
    "num_epochs = 10\n",
    "lossfunctions = [monai.losses.DiceLoss(sigmoid=True, include_background=False)]\n",
    "lossfunctionsnames = [\"Dice\"]\n",
    "roi_sizes = [128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff620e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "Seed = 2071293819 # 01111011011101010110111101111011 in binary\n",
    "monai.utils.set_determinism(seed=Seed) # set seed for model reproducibility\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(Seed)\n",
    "torch.cuda.manual_seed(Seed)\n",
    "\n",
    "# Ensure deterministic behavior pytorch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e41b0a-c670-440f-afc0-88399d635a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset Paths\n",
    "image_files = sorted(glob.glob(os.path.join(data_path_training_images, '*.tif')))\n",
    "mask_files = sorted(glob.glob(os.path.join(data_path_training_masks, '*.gif')))\n",
    "segmentation_files = sorted(glob.glob(os.path.join(data_path_training_segmentations, '*.gif')))\n",
    "\n",
    "# Split the dataset into training, validation and test sets\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(image_files[0:num_train_files], segmentation_files[0:num_train_files])]\n",
    "validation_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(image_files[num_train_files:num_train_files+num_validation_files], segmentation_files[num_train_files:num_train_files+num_validation_files])]\n",
    "test_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(image_files[num_train_files+num_validation_files:], segmentation_files[num_train_files+num_validation_files:])]\n",
    "\n",
    "def rgb_to_grayscale(img):\n",
    "    return img[..., 1]  # No need to add a channel dimension here\n",
    "\n",
    "def visualize_sample(sample, title1=None, title2=None):\n",
    "    # Visualize the x-ray and overlay the mask, using the dictionary as input\n",
    "    image = np.squeeze(sample['img'][0,0,:,:])\n",
    "    mask = np.squeeze(sample['seg'][0,0,:,:])\n",
    "    fig = plt.figure(figsize=[10,7])\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image, 'gray')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image, 'gray')\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    ax2.imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    if title1 is not None:\n",
    "        ax1.set_title(title1)\n",
    "    if title2 is not None:\n",
    "        ax2.set_title(title2)\n",
    "    plt.show()\n",
    "    \n",
    "class ThresholdTransform(Transform): # sets pixels less than a specified threshold to zero.\n",
    "    def __init__(self, keys, threshold):\n",
    "        self.keys = keys\n",
    "        self.threshold = threshold\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            img = data[key]\n",
    "            img[img < self.threshold] = 0\n",
    "            data[key] = img\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea48fda-c348-4d04-9bb4-d30fb99e9458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# added to visualize the data after pre-poscessing (after transformations)\n",
    "\n",
    "def visualize_five_samples_across_batches(data_loader):\n",
    "    # Prepare a figure to accommodate 5 images and their histograms\n",
    "    fig, axs = plt.subplots(5, 3, figsize=(18, 30))  # 5 rows (for each image), 3 columns (for image, mask, histogram)\n",
    "    \n",
    "    image_count = 0  # Track the number of images processed\n",
    "\n",
    "    # Iterate over batches until we have displayed 5 images\n",
    "    for batch in data_loader:\n",
    "        for i in range(batch['img'].shape[0]):\n",
    "            if image_count >= 5:\n",
    "                break  # Stop if we have already processed 5 images\n",
    "\n",
    "            # Extract image and mask\n",
    "            image = batch['img'][i]\n",
    "            mask = batch['seg'][i]\n",
    "\n",
    "            # Convert to numpy arrays\n",
    "            image_np = image.numpy().squeeze()\n",
    "            mask_np = mask.numpy().squeeze()\n",
    "\n",
    "            # Display the image\n",
    "            axs[image_count, 0].imshow(image_np, cmap='gray')\n",
    "            axs[image_count, 0].set_title(f'Image {image_count+1}')\n",
    "            axs[image_count, 0].axis('off')\n",
    "\n",
    "            # Display the mask\n",
    "            axs[image_count, 1].imshow(mask_np, cmap='gray')\n",
    "            axs[image_count, 1].set_title(f'Mask {image_count+1}')\n",
    "            axs[image_count, 1].axis('off')\n",
    "\n",
    "            # Display histogram of pixel values in the image\n",
    "            axs[image_count, 2].hist(image_np.flatten(), bins=50, color='gray')\n",
    "            axs[image_count, 2].set_title(f'Histogram of Image {image_count+1} Pixel Values')\n",
    "            axs[image_count, 2].set_xlabel('Pixel Value')\n",
    "            axs[image_count, 2].set_ylabel('Frequency')\n",
    "            axs[image_count, 2].set_xticks(np.arange(0, 1.1, 0.1))\n",
    "            axs[image_count, 2].grid(True)  # Add a grid to the histogram plot\n",
    "\n",
    "            image_count += 1  # Increment the count of images processed\n",
    "\n",
    "        if image_count >= 5:\n",
    "            break  # Exit the outer loop if 5 images have been processed\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37452325-a7a7-4624-89a5-d3ca4073303e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 16/16 [00:00<00:00, 32.24it/s]\n",
      "Loading dataset: 100%|██████████| 2/2 [00:00<00:00, 43.31it/s]\n",
      "Loading dataset: 100%|██████████| 2/2 [00:00<00:00, 43.42it/s]\n",
      "Training:  30%|███       | 3/10 [00:00<00:01,  5.79epochs/s]"
     ]
    }
   ],
   "source": [
    "# loop over loss functions and roi sizes, and save the resulting model at set epochs\n",
    "for index, loss_function in enumerate(lossfunctions):\n",
    "    for roi_size in roi_sizes:\n",
    "        # Data loaders and transforms\n",
    "        # Define Transformation\n",
    "        train_transform = Compose([\n",
    "            LoadImaged(keys=[\"img\", \"seg\"], reader='monai.data.ITKReader'),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"], channel_dim='no_channel'),\n",
    "            ScaleIntensityd(keys=[\"img\", 'seg']),\n",
    "            ThresholdTransform(keys=[\"img\"], threshold=0.07),\n",
    "            ToTensord(keys=[\"img\", \"seg\"]), \n",
    "            Lambdad(keys=[\"img\"], func=lambda x: rgb_to_grayscale(x)),\n",
    "            RandFlipd(keys=[\"img\", \"seg\"], prob=trans_prob, spatial_axis=1),\n",
    "            RandSpatialCropSamplesd(keys=[\"img\", \"seg\"], roi_size=[roi_size, roi_size], num_samples=1, random_size=False),\n",
    "        ])\n",
    "\n",
    "        validation_test_transform = Compose([\n",
    "            LoadImaged(keys=[\"img\", \"seg\"], reader='monai.data.ITKReader'),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"], channel_dim='no_channel'),\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            ThresholdTransform(keys=[\"img\"], threshold=0.07),\n",
    "            ToTensord(keys=[\"img\", \"seg\"]),\n",
    "            Lambdad(keys=[\"img\"], func=lambda x: rgb_to_grayscale(x)),\n",
    "        ])\n",
    "\n",
    "\n",
    "        # Create CacheDataset\n",
    "        train_data = CacheDataset(data=train_files, transform=train_transform)\n",
    "        validation_data = CacheDataset(data=validation_files, transform=validation_test_transform)\n",
    "        test_data = CacheDataset(data=test_files, transform=validation_test_transform)\n",
    "\n",
    "        # Create DataLoader\n",
    "        train_loader = DataLoader(train_data, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "        validation_loader = DataLoader(validation_data, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Model\n",
    "        model = UNet(\n",
    "            spatial_dims=2,           #input data is 2D\n",
    "            in_channels=1,            #input image has 1 channel (if RGB it would be 3)\n",
    "            out_channels=1,           # binairy segmentation, each pixel is one of 2 things\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),     # strides = how much spatial dimention is reduced\n",
    "            dropout=0,\n",
    "        )\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        inferer = monai.inferers.SlidingWindowInferer(roi_size=[roi_size, roi_size], overlap=0.5)\n",
    "        discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)     #converts logits to discrete binary values (0 or 1), with a threshold of 0.5\n",
    "        Sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        # Training loop\n",
    "        model_loss = np.zeros(num_epochs)\n",
    "        validation_loss = np.zeros(num_epochs)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        epoch = 0\n",
    "        with tqdm(range(num_epochs), unit=\"epochs\") as tqdm_iterator:\n",
    "            tqdm_iterator.set_description('Training{}'.format(''))\n",
    "\n",
    "            for i, epoch in enumerate(tqdm_iterator):\n",
    "                model.train()\n",
    "                training_steps=0\n",
    "                epoch_loss = 0\n",
    "                for batch_data in train_loader:\n",
    "                    training_steps+=1\n",
    "                    inputs, segmentations = batch_data['img'].to(device), batch_data['seg'].to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_function(outputs, segmentations)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                model_loss[epoch] = epoch_loss/training_steps\n",
    "                if (epoch+1) % validation_wait == 0:\n",
    "                    model.eval()\n",
    "                    validation_steps=0\n",
    "                    validation_epoch_loss = 0\n",
    "                    for batch_data in validation_loader:\n",
    "                        validation_steps+=1\n",
    "                        inputs, segmentations = batch_data['img'].to(device), batch_data['seg'].to(device)\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            outputs = inferer(inputs.to(device), network=model)\n",
    "\n",
    "                        loss = loss_function(outputs, segmentations)\n",
    "                        validation_epoch_loss += loss.item()\n",
    "                    validation_loss[(epoch-validation_wait+1):epoch+1] = validation_epoch_loss/validation_steps*np.ones(validation_wait)\n",
    "                    \n",
    "                    clear_output(wait=True)\n",
    "                    display(f'Epoch {epoch+1}/{num_epochs}, Loss: {model_loss[epoch]:.4f}, Validation loss: {validation_loss[epoch]:.4f}')\n",
    "                # if epoch+1 in num_epochssave:\n",
    "                #     # save model\n",
    "                #     torch.save(model, f\"Experiment results/model_loss{lossfunctionsnames[index]}_roisize{roi_size}_epoch{epoch+1}.pth\")\n",
    "        \n",
    "        # save loss\n",
    "        np.save(f\"Experiment results/model_loss{lossfunctionsnames[index]}_roisize{roi_size}_modelloss.npy\", model_loss)\n",
    "        np.save(f\"Experiment results/model_loss{lossfunctionsnames[index]}_roisize{roi_size}_validation  loss.npy\", validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9058e9f-c046-4af2-9e2b-374f677741a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(np.arange(1,num_epochs+1), model_loss)\n",
    "ax1.plot(np.arange(1,num_epochs+1), validation_loss)\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training loss Unet')\n",
    "ax1.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d915d-52d8-43d4-8360-5243eed9f592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('model_lossDiceCE_roisize128_epoch16000.pth')  # load the model from disk\n",
    "\n",
    "def visual_evaluation(sample, model):\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[roi_size, roi_size], overlap=0.5)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Perform inference once\n",
    "        output = inferer(sample['img'].to(device), network=model).cpu()\n",
    "        # Apply Sigmoid to get probabilities\n",
    "        probabilities = sigmoid(output)\n",
    "        # Apply discrete transformation for binary segmentation\n",
    "        model_segmentation = discrete_transform(probabilities)\n",
    "\n",
    "    ground_truth_segmentation = sample[\"seg\"][0, 0, :, :].squeeze()\n",
    "\n",
    "    TP = torch.sum((model_segmentation > 0.9) & (ground_truth_segmentation == 1)).float()\n",
    "    FN = torch.sum((model_segmentation < 0.1) & (ground_truth_segmentation == 1)).float()\n",
    "    TN = torch.sum((model_segmentation < 0.1) & (ground_truth_segmentation == 0)).float()\n",
    "    FP = torch.sum((model_segmentation > 0.9) & (ground_truth_segmentation == 0)).float()\n",
    "    \n",
    "    sensitivity = TP / (TP + FN + 1e-6)\n",
    "    specificity = TN / (TN + FP + 1e-6)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-6)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=[10, 10])\n",
    "\n",
    "    # Image\n",
    "    img_np = sample[\"img\"][0, 0, :, :].squeeze().numpy()\n",
    "    ax[0, 0].imshow(img_np, cmap='gray')\n",
    "    ax[0, 0].set_title('Image')\n",
    "\n",
    "    # Ground truth overlay\n",
    "    ground_truth_segmentation_np = ground_truth_segmentation.numpy()\n",
    "    ax[0, 1].imshow(ground_truth_segmentation_np, cmap='gray')\n",
    "    ax[0, 1].set_title('Ground Truth Segmentation')\n",
    "\n",
    "    # Prediction overlay\n",
    "    model_segmentation_np = model_segmentation[0, 0].numpy()\n",
    "    ax[1, 0].imshow(model_segmentation_np, cmap='gray')\n",
    "    ax[1, 0].set_title('Prediction')\n",
    "    \n",
    "    # Prediction with false positives and false negatives\n",
    "    ax[1, 1].imshow(img_np, cmap='gray')\n",
    "    \n",
    "    # False positive overlay\n",
    "    false_positives = (model_segmentation_np > 0.9) & (ground_truth_segmentation_np == 0)\n",
    "    false_positive_overlay = np.zeros_like(model_segmentation_np)\n",
    "    false_positive_overlay[false_positives] = 1\n",
    "\n",
    "    # False negative overlay\n",
    "    false_negatives = (model_segmentation_np < 0.1) & (ground_truth_segmentation_np == 1)\n",
    "    false_negative_overlay = np.zeros_like(model_segmentation_np)\n",
    "    false_negative_overlay[false_negatives] = 1\n",
    "\n",
    "    # Create RGB image for overlay\n",
    "    overlay = np.zeros((img_np.shape[0], img_np.shape[1], 3), dtype=np.float32)\n",
    "\n",
    "    # Add red for false positives\n",
    "    overlay[..., 0] = false_positive_overlay\n",
    "\n",
    "    # Add green for false negatives\n",
    "    overlay[..., 1] = false_negative_overlay\n",
    "\n",
    "    ax[1, 1].imshow(overlay, alpha=0.7)\n",
    "    ax[1, 1].set_title('Prediction with False Positives and False Negatives')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Sensitivity is {:.4f}\".format(sensitivity.item()))\n",
    "    print(\"Specificity is {:.4f}\".format(specificity.item()))\n",
    "    print(\"Accuracy is {:.4f}\".format(accuracy.item()))\n",
    "    print(\"Precision is {:.4f}\".format(precision.item()))\n",
    "    \n",
    "    print(\"Loss is {}\".format(loss_function(output, sample['seg'])))\n",
    "\n",
    "def compute_metric(dataloader, model, metric_fn):\n",
    "    \"\"\"\n",
    "    This function computes the average value of a metric for a data set.\n",
    "    \n",
    "    Args:\n",
    "        dataloader (monai.data.DataLoader): dataloader wrapping the dataset to evaluate.\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "        metric_fn (function): function computing the metric value from two tensors:\n",
    "            - a batch of outputs,\n",
    "            - the corresponding batch of ground truth masks.\n",
    "        \n",
    "    Returns:\n",
    "        (float) the mean value of the metric\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[roi_size, roi_size], overlap=0.5)\n",
    "    discrete_transform = monai.transforms.AsDiscrete(threshold=0.5)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    mean_value = 0       # initialize\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        with torch.no_grad():\n",
    "            output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu()))\n",
    "        mean_value += metric_fn(output, sample[\"seg\"])\n",
    "    return (torch.mean(mean_value) / len(dataloader)).item()\n",
    "\n",
    "# Assuming test_loader, test_data, model, roi_size, device, and loss_function are defined\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "visual_evaluation(next(iter(test_loader)), model)\n",
    "visual_evaluation(next(iter(test_loader)), model)\n",
    "\n",
    "\n",
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\")\n",
    "\n",
    "print('Mean Dice score is {}'.format(compute_metric(test_loader, model, dice_metric))) # This should return the Dice score on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model, f'model_epoch{num_epochs}_loss_Dice.pth')\t# save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de59f6e-9d1a-48ba-936e-3a1fb99f05b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute dice loss for all models\n",
    "# get all model names\n",
    "model_names = glob.glob('Experiment results/*.pth')\n",
    "# sort model names \n",
    "model_names.sort(key=lambda x: os.path.getmtime(x))\n",
    "print(model_names)\n",
    "# create array of model names\n",
    "model_names = np.array(model_names)\n",
    "# reshape model_names to 5x8\n",
    "model_names = model_names.reshape((8,5))\n",
    "# print(model_names)\n",
    "model_names_sorted = model_names.copy()\n",
    "model_names_sorted[2:,:]=model_names_sorted[1:-1,:]\n",
    "model_names_sorted[1,:]=model_names[-1,:]\n",
    "print(model_names_sorted)\n",
    "roi_sizes = [32, 64, 128, 256, 32, 64, 128, 256]\n",
    "# calculate dice loss for all models on test set\n",
    "dice_losses = np.zeros((8,5))\n",
    "for ii1, model_name_list in enumerate(model_names_sorted):\n",
    "    for ii2,model_name in enumerate(model_name_list):\n",
    "        model = torch.load(model_name)\n",
    "        model.eval()\n",
    "        inferer = monai.inferers.SlidingWindowInferer(roi_size=[roi_sizes[ii1], roi_sizes[ii1]], overlap=0.5)\n",
    "        discrete_transform = monai.transforms.AsDiscrete(threshold=0.5)\n",
    "        Sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        mean_value = 0       # initialize\n",
    "        \n",
    "        for sample in test_loader:\n",
    "            with torch.no_grad():\n",
    "                output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu()))\n",
    "            mean_value += dice_metric(output, sample[\"seg\"])\n",
    "        dice_losses[ii1,ii2] = (torch.mean(mean_value) / len(test_loader)).item()\n",
    "\n",
    "# save dice losses\n",
    "np.save('Experiment results/dice_losses.npy', dice_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure of dice score vs epoch for all models\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['b', 'g', 'r', 'c']\n",
    "print(dice_losses)\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    if i>3:\n",
    "        ax.plot(num_epochssave, dice_losses[i], label=f\"{model_names[i]}\", linestyle = 'dashed', color = colors[i-4], linewidth=2)\n",
    "        # ax.plot(num_epochssave, dice_losses[i], label=f\"{model_names[i]}\", linestyle = 'dashed', color = colors[i-4], linewidth=2)\n",
    "    else:\n",
    "        ax.plot(num_epochssave, dice_losses[i], label=f\"{model_names[i]}\", color = colors[i], linewidth=2)\n",
    "        # ax.plot(num_epochssave, dice_losses[i], label=f\"{model_names[i]}\", color = colors[i], linewidth=2)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Dice score')\n",
    "ax.legend(['Dice_32','Dice_64','Dice_128','Dice_256','DiceCE_32','DiceCE_64','DiceCE_128','DiceCE_256'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a078b6e-01d0-4e2b-b995-723b9000d4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_secret(sample, model, samplenr, roi_size):\n",
    "\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[roi_size, roi_size], overlap=0.5)\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu()))\n",
    " \n",
    "    fig, ax = plt.subplots(1, 2)  \n",
    "    \n",
    "    ax[0].imshow(sample[\"img\"][0,0,:,:].squeeze(), 'gray')   \n",
    "    ax[0].set_title('Image')\n",
    "\n",
    "    overlay_output = np.ma.masked_where(output[0, 0] == 0, output[0, 0])\n",
    "    print(overlay_output.shape)\n",
    "    ax[1].imshow(overlay_output[:,:], 'Reds', alpha = 1, clim=[0,1])\n",
    "    ax[1].set_title('Prediction')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    # save the output\n",
    "    savepath = f'testresults\\\\{samplenr}_secret.nii.gz'\n",
    "    writer = ITKWriter(output_dtype=output.dtype)\n",
    "\n",
    "    # Save the MetaTensor to a file\n",
    "    writer.set_data_array(output)\n",
    "    writer.write(savepath)\n",
    "\n",
    "secret_test_transform = Compose([\n",
    "            LoadImaged(keys=[\"img\"], reader='monai.data.ITKReader'),\n",
    "            EnsureChannelFirstd(keys=[\"img\"], channel_dim='no_channel'),\n",
    "            ScaleIntensityd(keys=[\"img\"]),\n",
    "            ThresholdTransform(keys=[\"img\"], threshold=0.07),\n",
    "            ToTensord(keys=[\"img\"]),\n",
    "            Lambdad(keys=[\"img\"], func=lambda x: rgb_to_grayscale(x)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42f475-7a64-4af1-a03c-501a3d532fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# secret test set:\n",
    "secret_test = sorted(glob.glob(os.path.join(data_path_secret_test, '*.tif')))\n",
    "print('secret test = ', secret_test)\n",
    "\n",
    "secret_test_files = [{\"img\": img} for img in zip(secret_test)]\n",
    "test_secret_data = CacheDataset(data=secret_test_files, transform=secret_test_transform)\n",
    "test_secret_loader = DataLoader(test_secret_data, num_workers=0, batch_size=1, shuffle=False)\n",
    "\n",
    "# load best model\n",
    "model = torch.load('Experiment results/model_lossDiceCE_roisize128_epoch16000.pth') # check which is best \n",
    "roi_size = 128\n",
    "for number, batch in enumerate(test_secret_loader):\n",
    "    print(batch[\"img\"].shape)\n",
    "    test_secret(batch, model, samplenr = number+41, roi_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
